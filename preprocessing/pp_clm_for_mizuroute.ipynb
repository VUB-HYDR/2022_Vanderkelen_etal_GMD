{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocessing of CLM simulation for MizuRoute\n",
    "INCLUDING: \n",
    "- 1. Processing of irrigation water demand as input for irrigation topology \n",
    "- 2. Inputfile preparation with runoff, precip and evaporation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import rasterstats\n",
    "import utils\n",
    "from iv_utils import *\n",
    "import netCDF4 as nc4\n",
    "\n",
    "# plot settings\n",
    "utils.set_plot_param()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialisation\n",
    "\n",
    "# model directory\n",
    "outdir = '/glade/scratch/ivanderk/'\n",
    "\n",
    "# current working directory\n",
    "scriptsdir = os.getcwd() + '/'\n",
    "\n",
    "# Define directory where processing is done -- subject to change\n",
    "procdir =  '/glade/work/ivanderk/data/'\n",
    "\n",
    "# mizuroute input dir (to save netcdf file to)\n",
    "mizuroute_dir = '/glade/work/ivanderk/mizuRoute_global/route/'\n",
    "\n",
    "# mizuroute data dir \n",
    "datadir = '/glade/work/ivanderk/data/'\n",
    "\n",
    "# go to processing directory \n",
    "os.chdir(procdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set case name\n",
    "case ='i.IHistClm50Sp.hcru_hcru.CTL'\n",
    "\n",
    "# run settings -- change this to terms directly? \n",
    "block = 'lnd'  # lnd data\n",
    "               # atm data\n",
    "               # rof data\n",
    "   \n",
    "    \n",
    "# define start and end year\n",
    "nspinupyears = 5\n",
    "spstartyear = '1960'   # spin up start year \n",
    "startyear   = str(int(spstartyear)+nspinupyears)   # start year, spin up excluded (5 years for now, best change to 10 when simulation is ready)\n",
    "endyear     = '2010'   # last year of the simulation\n",
    "\n",
    "\n",
    "# open network topology \n",
    "ntopo = xr.open_dataset(mizuroute_dir+'ancillary_data/ntopo_hdma_mod.reorder_lake_H06.nc')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Save irrigation demand seasonality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load time series of simulated variables from raw h0 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user settings\n",
    "stream = 'h0'  # h0 output block\n",
    "               # h1 output block\n",
    "               # h2 output block\n",
    "\n",
    "exclude_spinup = True\n",
    "\n",
    "variables =  ['QIRRIG_FROM_SURFACE']#, 'QRUNOFF'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading year 1965\r"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: b'/glade/scratch/ivanderk/archive/i.IHistClm50Sp.hcru_hcru.CTL/lnd/hist/i.IHistClm50Sp.hcru_hcru.CTL.clm2.h0.1965-02-01-00000.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda/envs/ctsm/lib/python3.7/site-packages/xarray/backends/file_manager.py\u001b[0m in \u001b[0;36m_acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/ctsm/lib/python3.7/site-packages/xarray/backends/lru_cache.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_to_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: [<class 'netCDF4._netCDF4.Dataset'>, ('/glade/scratch/ivanderk/archive/i.IHistClm50Sp.hcru_hcru.CTL/lnd/hist/i.IHistClm50Sp.hcru_hcru.CTL.clm2.h0.1965-02-01-00000.nc',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False))]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-de84bb9ce5f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# open file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mds_year\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiledir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfn_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# extract necessary variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/ctsm/lib/python3.7/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, backend_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0mdrop_variables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_variables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mdecoders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m     )\n\u001b[1;32m    507\u001b[0m     ds = _dataset_from_backend_dataset(\n",
      "\u001b[0;32m~/miniconda/envs/ctsm/lib/python3.7/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, format, clobber, diskless, persist, lock, autoclose)\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0mpersist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpersist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m             \u001b[0mautoclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautoclose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m         )\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/ctsm/lib/python3.7/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, filename, mode, format, group, clobber, diskless, persist, lock, lock_maker, autoclose)\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0mnetCDF4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         )\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautoclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautoclose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_acquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_lock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/ctsm/lib/python3.7/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_remote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_remote_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/ctsm/lib/python3.7/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36mds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_acquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mopen_store_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/ctsm/lib/python3.7/site-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36m_acquire\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_acquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_lock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneeds_lock\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m             \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_nc4_require_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/ctsm/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/ctsm/lib/python3.7/site-packages/xarray/backends/file_manager.py\u001b[0m in \u001b[0;36macquire_context\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0macquire_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_lock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;34m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_acquire_with_cache_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneeds_lock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/ctsm/lib/python3.7/site-packages/xarray/backends/file_manager.py\u001b[0m in \u001b[0;36m_acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    203\u001b[0m                     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                     \u001b[0;31m# ensure file doesn't get overriden when opened again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: b'/glade/scratch/ivanderk/archive/i.IHistClm50Sp.hcru_hcru.CTL/lnd/hist/i.IHistClm50Sp.hcru_hcru.CTL.clm2.h0.1965-02-01-00000.nc'"
     ]
    }
   ],
   "source": [
    "# load history file for every year, extract variables and concatenate timeseries\n",
    "\n",
    "variables = variables +  ['lat','lon','time','time_bounds']\n",
    "\n",
    "# set start year for load based on whether or not to exclude spin up\n",
    "if exclude_spinup:  load_startyear = startyear \n",
    "else: load_startyear = spstartyear\n",
    "\n",
    "# Define directory where timeseries data is stored\n",
    "filedir = outdir + 'archive/' + case + '/' + block + '/hist/'\n",
    "tspans = {'h0' : [str(year)+'-02-01-00000' for year in range(int(load_startyear),int(endyear)+1)],\n",
    "          'h1' : [str(year)+'-01-01-00000' for year in range(int(load_startyear),int(endyear)+1)], \n",
    "          'h2' : [str(year)+'-01-01-00000' for year in range(int(load_startyear),int(endyear)+1)]} \n",
    "\n",
    "# define filename\n",
    "for i, year in enumerate(range(int(load_startyear),int(endyear)+1)):\n",
    "    print('Loading year '+str(year),end='\\r')\n",
    "    fn_in = case + '.clm2.' + stream + '.' + tspans[stream][i] +'.nc'\n",
    "\n",
    "    # open file\n",
    "    ds_year = xr.open_dataset(filedir+fn_in)\n",
    "\n",
    "    # extract necessary variable \n",
    "    ds_sel = ds_year[variables]\n",
    "\n",
    "    # initialise data array\n",
    "    if i == 0:   ds = ds_sel\n",
    "    else:  ds = xr.concat([ds, ds_sel], dim=\"time\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and save irrigation seasonality in gridded format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save rolled variable\n",
    "\n",
    "da = ds.QIRRIG_FROM_SURFACE\n",
    "\n",
    "da_seascycle = da.groupby('time.month').mean()\n",
    "\n",
    "values = np.roll(da_seascycle.values,360, axis=2)\n",
    "\n",
    "da_roll = xr.DataArray(values, coords={'time':da_seascycle.month.values,'lat': da_seascycle.lat.values, 'lon':  da_seascycle.lon.values},\n",
    "             dims=['time','lat', 'lon'])\n",
    "\n",
    "da_roll['lon']  = da_roll['lon']-180\n",
    "\n",
    "#ds_seas = da_roll.to_dataset(name='QIRRIG')\n",
    "#da_hru_id = xr.open_dataset(mizuroute_dir+'input/I2000CLM50_exp1.clm2.h1.1980-2000.nc')['hru_id']\n",
    "#ds_seas['hru_id'] = da_hru_id\n",
    "#ds_seas.to_netcdf('irrig_seasonality/'+case+'.'+startyear+'-'+endyear+'.QIRRIG_seascycle_rolled.nc')\n",
    "\n",
    "# save per month\n",
    "months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "\n",
    "ds_per_month = xr.Dataset()\n",
    "\n",
    "for i,month in enumerate(months): \n",
    "    \n",
    "    da_month = xr.DataArray(da_roll[i,:,:], coords={'lat': da_roll.lat.values, 'lon':  da_roll.lon.values}, dims=['lat', 'lon'])\n",
    "    ds_per_month['QIRRIG_'+month] = da_month\n",
    "\n",
    "ds_per_month.to_netcdf(datadir+'irrig_seasonality/'+case+'.'+startyear+'-'+endyear+'.QIRRIG_seascycle.nc')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate mean irrigation for each hru for every month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "\n",
    "load_geometry_catch_global = False\n",
    "\n",
    "# load hru id info from catchment shpfile\n",
    "# really loading takes a long time! (therefore, load csv where geometry is already dropped)\n",
    "if load_geometry_catch_global:\n",
    "    catch = gpd.read_file(catch_file)\n",
    "    catch_ids = catch_global.drop(columns=['geometry'])\n",
    "    catch_ids.to_csv(datadir+'topology/HDMA_catchment/hdma_global_catch_v2_nogeom.csv')\n",
    "else: \n",
    "    catch_ids = pd.read_csv(datadir+'topology/HDMA_catchment/hdma_global_catch_v2_nogeom.csv')\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jun\n",
      "Jul\n",
      "Aug\n",
      "Sep\n",
      "Oct\n",
      "CPU times: user 1h 59min 16s, sys: 2h 36min 37s, total: 4h 35min 54s\n",
      "Wall time: 4h 36min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "months = ['Jun','Jul', 'Aug', 'Sep', 'Oct']\n",
    "# Calculate zonal statistics for every month and save in csv\n",
    "\n",
    "catch_file = datadir+'topology/HDMA_catchment/hdma_global_catch_v2.gpkg'\n",
    "nc_file = datadir+'irrig_seasonality/'+case+'.'+startyear+'-'+endyear+'.QIRRIG_seascycle.nc'\n",
    "\n",
    "for month in months: \n",
    "    print(month)\n",
    "    zonal_statistics = rasterstats.zonal_stats(catch_file, 'netcdf:'+nc_file+':QIRRIG_'+month)\n",
    "\n",
    "    means = []\n",
    "    [means.append(item['mean']) for item in zonal_statistics]; \n",
    "    catch_ids['QIRRIG_'+month] = means\n",
    "    catch_ids.to_csv(datadir+'irrig_seasonality/catch_QIRRIG_'+month+'.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save QIRRIG per hru in netcdf file (that will be used as input to apply irrigation topology)\n",
    "\n",
    "ds_qirrig_hru = xr.Dataset()\n",
    "\n",
    "df_ntopo = ntopo[['hruid']].to_dataframe()\n",
    "\n",
    "for i, month in enumerate(months): \n",
    "    catch_ids = pd.read_csv(datadir+'irrig_seasonality/catch_QIRRIG_'+month+'.csv')\n",
    "    df_ntopo_merged = df_ntopo.merge(catch_ids, on='hruid')\n",
    "    ds_qirrig_hru['QIRRIG_'+month] = xr.DataArray(df_ntopo_merged['QIRRIG_'+month], coords=[df_ntopo_merged.index.values], dims=[\"hru\"])\n",
    "\n",
    "fn = 'remap_monthly_QIRRIG_I2000Clm50Sp.hcru_hcru.nc'\n",
    "ds_qirrig_hru.to_netcdf(datadir+'irrig_seasonality/'+fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Make timeseries of daily CLM simulations and save as MizuRoute input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user settings\n",
    "stream = 'h1'              # h1 output block\n",
    "               # h2 output block\n",
    "\n",
    "exclude_spinup = True\n",
    "save_mizuroute_input = True\n",
    "\n",
    "variables = ['QIRRIG_FROM_SURFACE', 'QRUNOFF', 'RAIN_FROM_ATM'] \n",
    "variables = [ 'QRUNOFF', 'RAIN_FROM_ATM', 'QIRRIG_FROM_SURFACE']#,'SNOW'] \n",
    "variables = []\n",
    "startyear   = '1971'\n",
    "endyear     = '1996'   # last year of the simulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 5s, sys: 2min 17s, total: 3min 22s\n",
      "Wall time: 5min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# load history file for every year, extract variables and concatenate timeseries\n",
    "variables = variables +  ['lat','lon','time','time_bounds']\n",
    "\n",
    "# set start year for load based on whether or not to exclude spin up\n",
    "if exclude_spinup:  load_startyear = startyear \n",
    "else: load_startyear = spstartyear\n",
    "\n",
    "# Define directory where timeseries data is stored\n",
    "filedir = outdir + 'archive/' + case + '/' + block + '/hist/'\n",
    "tspans = {'h0' : [str(year)+'-02-01-00000' for year in range(int(load_startyear),int(endyear)+1)],\n",
    "          'h1' : [str(year)+'-01-01-00000' for year in range(int(load_startyear),int(endyear)+1)], \n",
    "          'h2' : [str(year)+'-01-01-00000' for year in range(int(load_startyear),int(endyear)+1)]} \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i, year in enumerate(range(int(load_startyear),int(endyear)+1)):\n",
    "\n",
    "    # load daily model output\n",
    "    stream = 'h1'\n",
    "    print('Loading year '+str(year),end='\\r')\n",
    "    fn_in = case + '.clm2.' + stream + '.' + tspans[stream][i] +'.nc'\n",
    "\n",
    "    # open file\n",
    "    ds_year = xr.open_dataset(filedir+fn_in)\n",
    "\n",
    "    # extract necessary variable \n",
    "    ds_sel = ds_year[variables]\n",
    "\n",
    "    # remove last timestep\n",
    "    #da = da[:-1,:,:]\n",
    "\n",
    "    # load subgrid output\n",
    "    # evaporation: load evaporation for lake landunit, apply vector to grid and save onto netcdf\n",
    "   \n",
    "    variable = 'EFLX_LH_TOT'\n",
    "    stream = 'h2'\n",
    "    fn_in = case + '.clm2.' + stream + '.' + tspans[stream][i] +'.nc'\n",
    "    outfile = case + '.clm2.' + stream + '.'+variable+'_lake.' + tspans[stream][i] +'.nc'\n",
    "    # do vector to grid conversion and select lake land unit\n",
    "\n",
    "    if not os.path.isfile(filedir+outfile):\n",
    "        ds_lunit =  lunit2grid(variable,filedir+fn_in,fn_in+outfile,select_lunit=5)\n",
    "    else: \n",
    "        ds_lunit = xr.open_dataset(filedir+outfile)\n",
    "        \n",
    "        #ds_lunit_lake = ds_lunit.sel(lunit=5)\n",
    "        #outfile_lake = case + '.clm2.' + stream + '.'+variable+'_lake.' + tspans[stream][i] +'.nc'\n",
    "        #ds_lunit_lake.to_netcdf(filedir+outfile_lake)\n",
    "        \n",
    "    da_lunit = ds_lunit[variable+'_lunit']\n",
    "    \n",
    "    ds_sel[variable+'_lake'] = da_lunit\n",
    "    \n",
    "    # store both in data array\n",
    "    if i == 0:   ds = ds_sel\n",
    "    else:  ds = xr.concat([ds, ds_sel], dim=\"time\")\n",
    "\n",
    "# Save variables in one file at MizuRoute input location\n",
    "if save_mizuroute_input: \n",
    "     # add hru_id to ds\n",
    "    da_hru_id = xr.open_dataset(mizuroute_dir+'input/I2000CLM50_exp1.clm2.h1.1980-2000.nc')['hru_id']\n",
    "    ds['hru_id'] = da_hru_id\n",
    "   \n",
    "    # convert latent heat flux into evaporation (mm/s) \n",
    "    # LHF [W/m²]= E [mm/s] * lvap [J/kg]\n",
    "    lvap = 2.45e6\n",
    "    ds['EVAP_lake'] = (ds['EFLX_LH_TOT_lake']/lvap)\n",
    "    ds['EVAP_lake'].attrs = {'long_name':'evaporation from lake land unit, converted from LHF of subgrid output', \n",
    "                        'units': 'mm/s'}\n",
    "    ds = ds.drop_vars('EFLX_LH_TOT_lake')#.astype('float32')\n",
    "  \n",
    "    fn_out = case+'.clm2.h1.'+startyear+'-'+endyear+'.nc'\n",
    "    ds.to_netcdf(mizuroute_dir+'input/'+fn_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_out = case+'.clm2.h1.'+startyear+'-'+endyear+'.nc'\n",
    "ds.to_netcdf(mizuroute_dir+'input/'+fn_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i.IHistClm50Sp.hcru_hcru.CTL.clm2.h1.1971-1996.nc'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## fIX evap lake to bigger dataset\n",
    "\n",
    "# continue from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('/glade/work/ivanderk/mizuRoute_global/route/input/i.IHistClm50Sp.hcru_hcru.CTL.clm2.h1.1971-2000.nc')\n",
    "ds.sel(time=slice(\"1971-01-01\", \"1996-12-31\")).to_netcdf('/glade/work/ivanderk/mizuRoute_global/route/input/i.IHistClm50Sp.hcru_hcru.CTL.clm2.h1.1971-1996.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_evap = xr.open_dataset(mizuroute_dir+'input/'+'i.IHistClm50Sp.hcru_hcru.CTL.clm2.h1.1971-1996_EVAP_lake.nc')['EVAP_lake']\n",
    "da_evap_masked = da_evap.where(da_evap!=0, np.nan)\n",
    "masked_values = da_evap_masked.to_masked_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the nc file to write\n",
    "ncid = nc4.Dataset('/glade/work/ivanderk/mizuRoute_global/route/input/i.IHistClm50Sp.hcru_hcru.CTL.clm2.h1.1971-1996.nc', \"a\", format=\"NETCDF4\")\n",
    "var_evap = ncid.createVariable('EVAP_lake','float32', ('time','lat','lon'),fill_value=1e+36)\n",
    "var_evap.long_name       = 'evaporation from lake land unit, converted from LHF of subgrid output'\n",
    "var_evap.units           = 'mm/s'\n",
    "var_evap.missing_value   = 1.e+36 \n",
    "\n",
    "var_evap[:] = masked_values\n",
    "ncid.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manipulating EFLX_LH_TOT data\n",
      "Time spend: 0:10:21.662639\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'variable' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'variable' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stream = 'h2'\n",
    "fn_in = case + '.clm2.' + stream + '.' + tspans[stream][i] +'.nc'\n",
    "infile = filedir+ fn_in\n",
    "outfile = filedir+case + '.clm2.' + stream + '.'+variable+'_lunit.' + tspans[stream][i] +'.nc'\n",
    "\n",
    "#outfile = filedir+'i.IHistClm50Sp.f09_g17.CTL.clm2.h2.TSA_lunit.189001-201412.nc'\n",
    "\n",
    "var  = 'EFLX_LH_TOT'\n",
    "\n",
    "# lunit vector to grid\n",
    "ds_lunit =  lunit2grid(var,infile,outfile=outfile)\n",
    "\n",
    "ds_sel = ds_lunit.isel(lunit=5)[variable+'_lunit'].to_dataset(name=variable+'_lake') \n",
    "da = ds_lunit[variable+'_lunit'].isel(lunit=5).mean('time').plot()\n",
    "\n",
    "# pft vector to grid\n",
    "#ds_lunit =  lunit2grid(var,infile,outfile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_out = case+'.clm2.h1.'+str(1981)+'-'+str(1990)+'.nc'\n",
    "\n",
    "ds =     xr.open_dataset(mizuroute_dir+'input/'+fn_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.DataArray &#x27;QRUNOFF&#x27; (time: 3650, lat: 360, lon: 720)&gt;\n",
       "[946080000 values with dtype=float32]\n",
       "Coordinates:\n",
       "    lunit    int64 ...\n",
       "  * lon      (lon) float32 0.25 0.75 1.25 1.75 ... 358.25 358.75 359.25 359.75\n",
       "  * lat      (lat) float32 -89.75 -89.25 -88.75 -88.25 ... 88.75 89.25 89.75\n",
       "  * time     (time) object 1981-01-01 00:00:00 ... 1990-12-31 00:00:00\n",
       "Attributes:\n",
       "    long_name:     total liquid runoff not including correction for land use ...\n",
       "    units:         mm/s\n",
       "    cell_methods:  time: mean</pre>"
      ],
      "text/plain": [
       "<xarray.DataArray 'QRUNOFF' (time: 3650, lat: 360, lon: 720)>\n",
       "[946080000 values with dtype=float32]\n",
       "Coordinates:\n",
       "    lunit    int64 ...\n",
       "  * lon      (lon) float32 0.25 0.75 1.25 1.75 ... 358.25 358.75 359.25 359.75\n",
       "  * lat      (lat) float32 -89.75 -89.25 -88.75 -88.25 ... 88.75 89.25 89.75\n",
       "  * time     (time) object 1981-01-01 00:00:00 ... 1990-12-31 00:00:00\n",
       "Attributes:\n",
       "    long_name:     total liquid runoff not including correction for land use ...\n",
       "    units:         mm/s\n",
       "    cell_methods:  time: mean"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['QRUNOFF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_lh = xr.open_dataset('/glade/scratch/ivanderk/archive/i.IHistClm50Sp.hcru_hcru.CTL/lnd/hist/i.IHistClm50Sp.hcru_hcru.CTL.clm2.h2.EFLX_LH_TOT_lake.1971-01-01-00000.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.DataArray &#x27;EFLX_LH_TOT_lunit&#x27; (time: 365, lat: 360, lon: 720)&gt;\n",
       "[94608000 values with dtype=float64]\n",
       "Coordinates:\n",
       "  * time     (time) object 1971-01-01 00:00:00 ... 1971-12-31 00:00:00\n",
       "  * lat      (lat) float32 -89.75 -89.25 -88.75 -88.25 ... 88.75 89.25 89.75\n",
       "  * lon      (lon) float32 0.25 0.75 1.25 1.75 ... 358.25 358.75 359.25 359.75\n",
       "    lunit    int64 ...\n",
       "Attributes:\n",
       "    long_name:     total latent heat flux [+ to atm]\n",
       "    units:         W/m^2\n",
       "    cell_methods:  time: mean</pre>"
      ],
      "text/plain": [
       "<xarray.DataArray 'EFLX_LH_TOT_lunit' (time: 365, lat: 360, lon: 720)>\n",
       "[94608000 values with dtype=float64]\n",
       "Coordinates:\n",
       "  * time     (time) object 1971-01-01 00:00:00 ... 1971-12-31 00:00:00\n",
       "  * lat      (lat) float32 -89.75 -89.25 -88.75 -88.25 ... 88.75 89.25 89.75\n",
       "  * lon      (lon) float32 0.25 0.75 1.25 1.75 ... 358.25 358.75 359.25 359.75\n",
       "    lunit    int64 ...\n",
       "Attributes:\n",
       "    long_name:     total latent heat flux [+ to atm]\n",
       "    units:         W/m^2\n",
       "    cell_methods:  time: mean"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_lh['EFLX_LH_TOT_lunit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda-ctsm]",
   "language": "python",
   "name": "conda-env-miniconda-ctsm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
