{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "broadband-secretary",
   "metadata": {},
   "source": [
    "# Prepare global input data for MizuRoute with Döll \n",
    "Inne Vanderkelen - March 2021\n",
    "\n",
    "#### Map reservoir parameters onto global river and catchment topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cross-halifax",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load modules\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import netCDF4 as nc4\n",
    "import numpy as np\n",
    "import os \n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "colored-yield",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load global river topo\n",
    "data_dir = './data_for_mizuroute/'\n",
    "\n",
    "ds_ntopo = xr.open_dataset(data_dir+'ntopo_hdma_mod.reorder_lake.nc')\n",
    "\n",
    "# shapefile also containing lake_id\n",
    "river_with_lake_dir = data_dir+'/river_with_lake_flag4_reorder/'\n",
    "# updated HDMA topology including lakes up to 10 km²\n",
    "gpd_river = gpd.read_file(data_dir+'/HDMA_hydrolakes10km_reorder/river_with_lake_flag4_10km_reorder.shp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "classical-cartoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add lake model to shapefile: 0: no lake model, 1: Döll, 2: Hanasaki\n",
    "gpd_river_D03 = gpd_river\n",
    "gpd_river_D03['lake_model'] = 0\n",
    "gpd_river_D03['ISLAKE'] = 0\n",
    "gpd_river_D03['RATECVA'] = 0\n",
    "gpd_river_D03['RATECVB'] = 0\n",
    "\n",
    "\n",
    "# add reservoirs as Hanasaki\n",
    "#gpd_river_D03.loc[gpd_river_D03['lakeId'].isin(list(gpd_grand['lakeId'].values)),'lake_model'] = 1\n",
    "#gpd_river_D03.loc[(gpd_river_D03['islake'] ==1) & (~gpd_river_D03['lakeId'].isin(list(gpd_grand['lakeId'].values))),'lake_model'] = 1\n",
    "gpd_river_D03.loc[gpd_river_D03['islake'] ==1,'lake_model'] = 1\n",
    "gpd_river_D03.loc[gpd_river_D03['islake'] ==1,'ISLAKE'] = 1\n",
    "\n",
    "gpd_river_D03.loc[gpd_river_D03['islake'] ==1,'RATECVA'] = ds_ntopo['RATECVA'].max().values # coefficient\n",
    "gpd_river_D03.loc[gpd_river_D03['islake'] ==1,'RATECVB'] = 1.5 # power\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "demographic-distance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write netcdf file with H06 parameters to merge to existing topology\n",
    "\n",
    "# define the shapefile\n",
    "shp = gpd_river_D03\n",
    "\n",
    "# open the nc file to write\n",
    "ncid = nc4.Dataset(data_dir+'HDMA_D03_parameters.nc', \"w\", format=\"NETCDF4\")\n",
    "# the dimension of the nc file variables is equal to the row of the shapefile\n",
    "dimid_seg = ncid.createDimension('seg',len(ds_ntopo.seg))\n",
    "\n",
    "# define the variable segId\n",
    "varid = ncid.createVariable('lakeId','i8',('seg',),fill_value=-1) #assuming all the fields are ints\n",
    "# Attributes\n",
    "varid.long_name      = 'lakeId corresponding to HydroLAKES and GRanD'\n",
    "varid.unit           = '-'\n",
    "# assign the values\n",
    "temp = np.array(shp['lakeId']); temp = temp.astype(int)\n",
    "varid[:] = temp\n",
    "\n",
    "\n",
    "# define the variable lake_model\n",
    "varid = ncid.createVariable('lake_model','i8',('seg',),fill_value=-1) #assuming all the fields are ints\n",
    "# Attributes\n",
    "varid.long_name      = 'Lake model used (1: Döll, natural lakes; 2: Hanasaki, reservoirs)'\n",
    "varid.unit           = '-'\n",
    "# assign the values\n",
    "temp = np.array(shp['lake_model']); temp = temp.astype(int)\n",
    "varid[:] = temp\n",
    "\n",
    "\n",
    "# define the variable lake_Vol\n",
    "varid = ncid.createVariable('lakeVol','f8',('seg',),fill_value=-9999) #assuming all the fields are floats\n",
    "# Attributes\n",
    "varid.long_name      = 'Maximum lake storage'\n",
    "varid.unit           = '-'\n",
    "# assign the values\n",
    "temp = np.array(shp['lake_Vol']) * 1000000 + 1 # 1 is to avoid division by zero\n",
    "varid[:] = temp\n",
    "\n",
    "# define the variable ISLAKE\n",
    "varid = ncid.createVariable('ISLAKE','i8',('seg',),fill_value=-9999) #assuming all the fields are floats\n",
    "# Attributes\n",
    "varid.long_name      = ''\n",
    "varid.unit           = '-'\n",
    "# assign the values\n",
    "temp = np.array(shp['ISLAKE'])\n",
    "varid[:] = temp\n",
    "\n",
    "# define the variable RATECVA\n",
    "varid = ncid.createVariable('RATECVA','f8',('seg',),fill_value=-9999) #assuming all the fields are floats\n",
    "# Attributes\n",
    "varid.long_name      = 'coefficient for storage-discharge relationship power'\n",
    "varid.unit           = '-'\n",
    "# assign the values\n",
    "temp = np.array(shp['RATECVA']) \n",
    "varid[:] = temp\n",
    "  \n",
    "    \n",
    "# define the variable RATECVA\n",
    "varid = ncid.createVariable('RATECVB','f8',('seg',),fill_value=-9999) #assuming all the fields are floats\n",
    "# Attributes\n",
    "varid.long_name      = 'power for storage-discharge relationship power'\n",
    "varid.unit           = '-'\n",
    "# assign the values\n",
    "temp = np.array(shp['RATECVB']) \n",
    "varid[:] = temp    \n",
    "    \n",
    "ncid.Conventions = 'CF-1.6'\n",
    "ncid.License     = 'The data were written by Inne Vanderkelen. They are under GPL.'\n",
    "ncid.history     = 'Created ' + time.ctime(time.time())\n",
    "ncid.source      = 'Written by prepare_globalinput_natlake.ipynb notebook'\n",
    "ncid.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "relevant-forty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge Döll parameters in network topology\n",
    "ds_D03_param = xr.open_dataset(data_dir + 'HDMA_D03_parameters.nc')\n",
    "\n",
    "# correct for spaces in front of the PFAF code\n",
    "#seg_pfafs = ds_ntopo['PFAF'].to_dataframe()\n",
    "#seg_pfafs['PFAF'] = np.char.strip( seg_pfafs['PFAF'].values.astype(str))\n",
    "#ds_ntopo['PFAF'] = seg_pfafs['PFAF']\n",
    "\n",
    "ds_ntopo = ds_D03_param.merge(ds_ntopo, compat='override').to_netcdf(data_dir+'ntopo_hdma_mod.reorder_lake_D03.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "attractive-asian",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(data_dir+'ntopo_hdma_mod.reorder_lake_D03.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-decision",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda-ctsm]",
   "language": "python",
   "name": "conda-env-miniconda-ctsm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
