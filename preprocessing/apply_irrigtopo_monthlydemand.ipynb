{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f56a7ca8",
   "metadata": {},
   "source": [
    "# Apply the global irrigation topology to get mean monthly demands\n",
    "Inne Vanderkelen - March 2021\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4224163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\r\n",
    "import numpy as np\r\n",
    "import geopandas as gpd\r\n",
    "import pickle\r\n",
    "import xarray as xr\r\n",
    "import warnings\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "warnings.filterwarnings('ignore')\r\n",
    "\r\n",
    "# add path where utils modules are located to python path\r\n",
    "import sys\r\n",
    "sys.path.append('C:\\\\Users\\\\ivand\\\\OneDrive - Vrije Universiteit Brussel\\\\PhD\\\\3_reservoir_release\\\\')\r\n",
    "\r\n",
    "# import own functions\r\n",
    "import pfaf.pfafstetter as pfaf # decode package from Naoki, see https://github.com/nmizukami/pfaf_decode \r\n",
    "from utils_plotting import *\r\n",
    "from utils_irrigtopo import *\r\n",
    "\r\n",
    "\r\n",
    "# Settings: \r\n",
    "outlet_threshold = 700e3 # in m\r\n",
    "tributary_threshold = 100e3 # m\r\n",
    "\r\n",
    "data_dir = 'C:\\\\Users\\\\ivand\\\\OneDrive - Vrije Universiteit Brussel\\\\PhD\\\\3_reservoir_release\\\\data_for_mizuroute\\\\'\r\n",
    "\r\n",
    "# define reservoir dependency dataset\r\n",
    "res_dependency = 'res_dependency_HDMA_outletthres_700km_tribthres_100km.pkl'\r\n",
    "# calculate or load reservoir dependency \r\n",
    "calc_res_dependency = False # if True: Calculate, if False: load\r\n",
    "\r\n",
    "# irr demand sensitivity\r\n",
    "sensitivity=\"_obsscaled\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86348e8c",
   "metadata": {},
   "source": [
    "## 1. Open river topology and get hrus with ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f351bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open river topology and get hrus with ids\r\n",
    "ntopo = xr.open_dataset(data_dir+'ntopo_hdma_mod.reorder_lake_H06.nc')\r\n",
    "\r\n",
    "# get pfafs corresponding to segments to hrus trough hru_seg_id\r\n",
    "seg_pfafs = ntopo[['PFAF','seg_id']].to_dataframe()\r\n",
    "# correct for spaces in front of the PFAF code\r\n",
    "seg_pfafs['PFAF'] = np.char.strip( seg_pfafs['PFAF'].values.astype(str))\r\n",
    "\r\n",
    "hrus_ids = ntopo[['hru_seg_id','hruid','Basin_Area']].to_dataframe()\r\n",
    "hrus = hrus_ids.merge(seg_pfafs,left_on='hru_seg_id',right_on=('seg_id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5a792e",
   "metadata": {},
   "source": [
    "## 2. Load irrigation amounts per hru and merge to hru dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd381fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load remapped irrigation as pandas dataframe and add basinIrrig to main hrus dataframe\r\n",
    "ds_hru_irrig = xr.open_dataset(data_dir + 'CLM_HDMA_remapped_monmean_1971-2000'+sensitivity+'.nc')\r\n",
    "# rename variable per month\r\n",
    "months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\r\n",
    "ds_hru_irrig_month = xr.Dataset()\r\n",
    "for i,month in enumerate(months): \r\n",
    "    da_month = ds_hru_irrig['QIRRIG'][i,:]\r\n",
    "    ds_hru_irrig_month['QIRRIG_'+month] = da_month\r\n",
    "\r\n",
    "hru_irrig = ds_hru_irrig_month.to_dataframe()\r\n",
    "hru_irrig = hru_irrig.merge(pd.read_csv(data_dir+'remap/lookup_ID_hruid.csv').drop_duplicates(), on='ID')\r\n",
    "hrus_irrig = hrus.merge(hru_irrig, on='hruid')\r\n",
    "\r\n",
    "# convert from mm/s to mÂ³/s by multiplying with basin area\r\n",
    "for month in months: \r\n",
    "    hrus_irrig['QIRRIG_'+month] =  hrus_irrig['QIRRIG_'+month] * 10**(-3) * hrus_irrig['Basin_Area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ef9b722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open res dependency\r\n",
    "with open(data_dir+\"irrigation_topology/\"+res_dependency, 'rb') as handle:\r\n",
    "    res_dependency_dict = pickle.load(handle)\r\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32b8b831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jan\n",
      "Calculating demand for reservoir 484 of 484\n",
      "Feb\n",
      "Calculating demand for reservoir 484 of 484\n",
      "Mar\n",
      "Calculating demand for reservoir 484 of 484\n",
      "Apr\n",
      "Calculating demand for reservoir 484 of 484\n",
      "May\n",
      "Calculating demand for reservoir 484 of 484\n",
      "Jun\n",
      "Calculating demand for reservoir 484 of 484\n",
      "Jul\n",
      "Calculating demand for reservoir 484 of 484\n",
      "Aug\n",
      "Calculating demand for reservoir 484 of 484\n",
      "Sep\n",
      "Calculating demand for reservoir 484 of 484\n",
      "Oct\n",
      "Calculating demand for reservoir 484 of 484\n",
      "Nov\n",
      "Calculating demand for reservoir 484 of 484\n",
      "Dec\n",
      "Wall time: 3min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\r\n",
    "\r\n",
    "demand_df = pd.DataFrame(index=list(res_dependency_dict.keys()))\r\n",
    "demand_df.index.name = 'PFAF'\r\n",
    "\r\n",
    "for month in months: \r\n",
    "\r\n",
    "    print('', end='\\n' )\r\n",
    "    print(month, end='\\n' )\r\n",
    "\r\n",
    "    demand_month = [] \r\n",
    "    count = 1\r\n",
    "\r\n",
    "    for reservoir in res_dependency_dict: \r\n",
    "        print('Calculating demand for reservoir '+str(count)+ ' of '+str(len(res_dependency_dict)),end='\\r' )\r\n",
    "\r\n",
    "        demand_tot = 0\r\n",
    "        # calculate sum over all river segments with weights applied\r\n",
    "        seg_to_sum = list(res_dependency_dict[reservoir].keys())\r\n",
    "        weights = list(res_dependency_dict[reservoir].values())\r\n",
    "        demand_tot = (hrus_irrig.loc[hrus_irrig['PFAF'].isin(seg_to_sum), 'QIRRIG_'+month].values * weights).sum()\r\n",
    "        # store in dict per reservoir\r\n",
    "        demand_month.append(demand_tot)\r\n",
    "\r\n",
    "        count = count+1\r\n",
    "    demand_df['H06_D_'+month] = demand_month\r\n",
    "\r\n",
    "# replace inf values with original demand values. \r\n",
    "demand_df_or = pd.read_csv(data_dir+'reservoirs_monthly_demand.csv', index_col='PFAF')    \r\n",
    "demand_df_nan = demand_df.replace(np.inf, np.nan)\r\n",
    "demand_df_nan.index = demand_df_nan.index.astype('int64')\r\n",
    "demand_df_nan = demand_df_nan.combine_first(demand_df_or)\r\n",
    "\r\n",
    "\r\n",
    "demand_df_nan.to_csv(data_dir+'reservoirs_monthly_demand'+sensitivity+'.csv')\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1128d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6aee2cdf9ae720feceda96379d915652886613d5be34c26e3e248aabd7d5919"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
